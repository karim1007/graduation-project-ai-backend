[
 
  {
    "question": "Explain the importance of using strong passwords in cybersecurity and describe at least three characteristics that make a password strong.",
    "answer": "Strong passwords are crucial in cybersecurity because they help protect personal and organizational information from unauthorized access. Weak passwords can be easily guessed or cracked by attackers using methods like brute force attacks or social engineering, leading to data breaches, identity theft, and other security incidents. A strong password typically has the following characteristics: 1) Length: It should be at least 12 characters long to increase the number of possible combinations. 2) Complexity: It should include a mix of uppercase and lowercase letters, numbers, and special characters to make it harder to guess. 3) Unpredictability: It should avoid common words, phrases, or easily guessable information such as birthdays or names. By using strong passwords, individuals and organizations can significantly reduce the risk of cyber attacks and protect sensitive information.",
    "type": "essay",
    "difficulty": "easy",
    "domain": "cybersecurity"
  },
  {
    "question": "Write a Python program that creates a custom TCP server which listens on a specified port and implements a simple handshake protocol: when a client connects, the server expects to receive the string 'HELLO'. If received, it responds with 'WELCOME' and then continuously echoes back any subsequent messages from the client until the client sends 'GOODBYE', upon which the server closes the connection. Include proper error handling and use the socket library.",
    "answer": "```python\nimport socket\n\nHOST = '0.0.0.0'  # Listen on all interfaces\nPORT = 65432       # Arbitrary non-privileged port\n\nwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as server_socket:\n    server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    server_socket.bind((HOST, PORT))\n    server_socket.listen()\n    print(f'Server listening on {HOST}:{PORT}')\n\n    while True:\n        try:\n            client_socket, client_address = server_socket.accept()\n            with client_socket:\n                print(f'Connected by {client_address}')\n                data = client_socket.recv(1024).decode('utf-8')\n                if data != 'HELLO':\n                    print(f'Unexpected handshake message: {data}')\n                    client_socket.close()\n                    continue\n                client_socket.sendall('WELCOME'.encode('utf-8'))\n\n                while True:\n                    message = client_socket.recv(1024).decode('utf-8')\n                    if not message:\n                        print('Client disconnected unexpectedly')\n                        break\n                    if message == 'GOODBYE':\n                        print('Client requested to close connection')\n                        break\n                    # Echo back the message\n                    client_socket.sendall(message.encode('utf-8'))\n\n        except Exception as e:\n            print(f'An error occurred: {e}')\n```",
    "type": "coding",
    "difficulty": "hard",
    "domain": "networking"
  },
  {
    "question": "True or False: Zero is an even number.",
    "answer": "True. Zero is considered an even number because it is divisible by 2 with no remainder (0 \u00f7 2 = 0). Even numbers are integers that can be expressed as 2k, where k is an integer, and since 0 = 2 \u00d7 0, zero fits this definition.",
    "type": "true_false",
    "difficulty": "easy",
    "domain": "mathematics"
  },
  {
    "question": "Which of the following is a common type of supervised learning task in machine learning?",
    "answer": "Classification is a common type of supervised learning task where the model learns to assign input data into predefined categories or classes based on labeled training data.",
    "type": "mcq",
    "difficulty": "easy",
    "domain": "machine learning"
  },
  {
    "question": "Discuss the concept of greedy algorithms in problem-solving. Explain how they differ from dynamic programming approaches, and provide an example problem where a greedy algorithm provides an optimal solution, as well as an example where it fails to do so.",
    "answer": "Greedy algorithms are a class of algorithms that make a sequence of choices, each of which looks the best at the moment, with the hope that these local optimizations will lead to a global optimum. The key characteristic is that once a choice is made, it is never reconsidered. This approach is usually simpler and faster than other methods. However, it does not guarantee an optimal solution for all problems.\n\nIn contrast, dynamic programming solves problems by breaking them down into overlapping subproblems, solving each subproblem once, and storing the results to avoid redundant computations. Dynamic programming guarantees finding the optimal solution by exploring all possible decisions systematically.\n\nAn example where a greedy algorithm provides an optimal solution is the Activity Selection Problem. Here, given a set of activities with start and finish times, the greedy approach of always selecting the next activity that finishes earliest leads to the maximum number of non-overlapping activities.\n\nAn example where a greedy algorithm fails is the Coin Change Problem with arbitrary coin denominations. For instance, given coin denominations of 1, 3, and 4 units, and a target amount of 6, a greedy approach that picks the largest coin first would select a 4-unit coin and then two 1-unit coins (total 3 coins), whereas the optimal solution is two 3-unit coins (2 coins). In such cases, dynamic programming is needed to find the minimal number of coins.\n\nIn summary, greedy algorithms are efficient but limited to problems where local optimal choices lead to global optima, while dynamic programming is more general but computationally heavier.",
    "type": "essay",
    "difficulty": "medium",
    "domain": "algorithms"
  },
  {
    "question": "Which SQL statement is used to retrieve data from a database?",
    "answer": "The SELECT statement is used to retrieve data from a database. It allows users to specify which columns to fetch and from which table(s). For example, `SELECT * FROM Employees;` retrieves all columns and rows from the Employees table.",
    "type": "mcq",
    "difficulty": "easy",
    "domain": "databases"
  },
  {
    "question": "Discuss the concept of overfitting in machine learning models. Explain the causes and consequences of overfitting, describe at least three techniques used to prevent or mitigate it, and analyze how these techniques impact model complexity and generalization performance.",
    "answer": "Overfitting occurs when a machine learning model learns not only the underlying patterns in the training data but also the noise, leading to poor generalization on unseen data. It typically arises when a model is excessively complex relative to the amount and noise level of training data, such as deep neural networks with many parameters trained on small datasets. The consequences include high accuracy on training data but significantly reduced performance on validation or test data, rendering the model unreliable for real-world applications.\n\nCauses of overfitting include high model complexity, insufficient training data, noisy or irrelevant features, and inadequate regularization. Overfitting undermines the goal of predictive modeling, which is to generalize well beyond the training set.\n\nThree common techniques to prevent or mitigate overfitting are:\n\n1. **Regularization:** Methods like L1 (Lasso) and L2 (Ridge) regularization add penalty terms to the loss function based on the magnitude of model parameters, discouraging overly complex models by shrinking coefficients toward zero. This reduces variance and helps improve generalization.\n\n2. **Cross-validation:** Techniques such as k-fold cross-validation provide a robust estimate of model performance on unseen data by repeatedly training and evaluating the model on different subsets of the data. This helps in tuning hyperparameters to find the right complexity balance.\n\n3. **Early stopping:** During iterative training (e.g., gradient descent), model performance on a validation set is monitored. Training halts once validation error starts increasing, preventing the model from fitting noise in the training data.\n\nOther techniques include dropout in neural networks, data augmentation, and pruning in decision trees.\n\nThese methods impact model complexity and generalization by effectively constraining the hypothesis space the model can represent. Regularization reduces effective complexity by penalizing large weights, early stopping limits training time to avoid memorization, and cross-validation guides the selection of hyperparameters that balance bias and variance. The net effect is improved generalization, where the model captures true underlying patterns rather than noise, enhancing predictive performance on new data.",
    "type": "essay",
    "difficulty": "hard",
    "domain": "machine learning"
  },
  {
    "question": "In a balanced AVL tree, after performing an insertion that causes a left-right (LR) imbalance at a node, which sequence of rotations correctly restores the AVL balance property?",
    "answer": "The correct sequence to fix a left-right (LR) imbalance is first a left rotation on the left child of the unbalanced node, followed by a right rotation on the unbalanced node itself. Specifically, if the imbalance occurs at node A with left child B and the new node inserted into the right subtree of B, then perform a left rotation on B, transforming the structure, and then perform a right rotation on A to restore the AVL balance property. This double rotation ensures that heights are adjusted correctly and the tree remains balanced.",
    "type": "mcq",
    "difficulty": "hard",
    "domain": "data structures"
  },
  {
    "question": "Explain the purpose of the OSI model in networking. Describe its seven layers and discuss how this model helps in understanding and designing network protocols.",
    "answer": "The OSI (Open Systems Interconnection) model is a conceptual framework used to understand and implement network communications by dividing the process into seven distinct layers. Its main purpose is to standardize networking functions to enable interoperability between different systems and technologies. The seven layers are:\n\n1. Physical Layer: Deals with the transmission of raw bit streams over physical media, including cables and switches.\n2. Data Link Layer: Responsible for node-to-node data transfer, error detection and correction, and framing.\n3. Network Layer: Manages routing, addressing, and packet forwarding across multiple networks.\n4. Transport Layer: Ensures reliable data transfer between hosts, providing error recovery and flow control.\n5. Session Layer: Manages sessions or connections between applications, including establishment, maintenance, and termination.\n6. Presentation Layer: Translates data formats, encryption, and compression to ensure data is readable by the receiving system.\n7. Application Layer: Provides network services directly to end-user applications, such as email, file transfer, and web browsing.\n\nBy dividing networking into these layers, the OSI model helps designers and engineers understand where specific protocols and technologies operate. It also promotes modularity, allowing changes in one layer without affecting others, simplifying troubleshooting, development, and education in networking.",
    "type": "essay",
    "difficulty": "easy",
    "domain": "networking"
  },
  {
    "question": "True or False: The time complexity of the QuickSort algorithm in the worst case is O(n\u00b2), but its average-case time complexity is O(n log n).",
    "answer": "True. QuickSort has a worst-case time complexity of O(n\u00b2), which occurs when the pivot selection consistently results in highly unbalanced partitions (e.g., always choosing the smallest or largest element as pivot). However, its average-case time complexity is O(n log n), making it efficient for most practical use cases.",
    "type": "true_false",
    "difficulty": "medium",
    "domain": "algorithms"
  },
  {
    "question": "Discuss the role of indexing in database systems. Compare and contrast B-tree and bitmap indexes in terms of their structure, use cases, advantages, and limitations. Additionally, analyze how the choice of indexing strategy can impact query performance and storage overhead in large-scale data warehouses.",
    "answer": "Indexing in database systems is a critical technique used to improve the speed of data retrieval operations. An index is a data structure that allows the database engine to find rows faster without scanning the entire table. Indexes work similarly to the index of a book, pointing to the location of desired data efficiently.\n\nTwo common types of indexes are B-tree indexes and bitmap indexes. \n\nB-tree indexes are balanced tree data structures that maintain sorted data and allow searches, sequential access, insertions, and deletions in logarithmic time. Each node in a B-tree contains keys and pointers to child nodes, organizing data hierarchically. B-tree indexes are suitable for high-cardinality columns (columns with many unique values), such as primary keys or unique identifiers. They perform well with range queries and equality searches. Their advantages include efficient handling of dynamic data that frequently changes and relatively low overhead for insertions and deletions. However, B-tree indexes can become large in size, particularly with very large tables, and may require more maintenance during heavy write operations.\n\nBitmap indexes, on the other hand, use bit arrays (bitmaps) and are especially efficient for columns with low cardinality (few distinct values) such as gender, status flags, or categorical attributes. Each distinct value in the column has an associated bitmap, where each bit represents a row in the table; a bit set to 1 indicates the presence of the value in that row. Bitmap indexes allow very fast bitwise operations (AND, OR, NOT) to combine multiple conditions, making them ideal for complex ad hoc queries common in data warehousing and OLAP (Online Analytical Processing). Their advantages include compact storage for low-cardinality data and efficient multi-dimensional queries. Limitations include poor performance in environments with frequent updates or inserts because modifying bitmaps can be costly, and they are not suitable for high-cardinality columns.\n\nThe choice of indexing strategy impacts query performance and storage overhead significantly. B-tree indexes offer balanced performance for transactional systems where write operations are frequent, and queries often involve range scans or unique lookups. Bitmap indexes optimize read-heavy environments with complex query predicates over categorical data, such as large-scale data warehouses. However, bitmap indexes can consume less space when cardinality is low but may grow prohibitively large if cardinality increases.\n\nIn summary, effective indexing requires understanding both the data characteristics and query patterns. Using B-tree indexes on columns with high cardinality and frequent writes ensures balanced performance, while bitmap indexes excel in read-intensive, low-cardinality environments where complex query filtering is common. Poor indexing choices can lead to slow queries, increased I/O, and excessive storage use, highlighting the importance of tailored indexing strategies in large-scale databases.",
    "type": "essay",
    "difficulty": "hard",
    "domain": "databases"
  },
  {
    "question": "True or False: In software development, version control systems help multiple developers collaborate by tracking changes to source code over time.",
    "answer": "True. Version control systems (VCS) such as Git track changes to source code, allowing multiple developers to collaborate efficiently by managing different versions, merging changes, and maintaining a history of the project\u2019s evolution.",
    "type": "true_false",
    "difficulty": "easy",
    "domain": "software engineering"
  },
  {
    "question": "True or False: In Python, the expression `5 / 2` returns an integer value.",
    "answer": "False. In Python 3, the division operator `/` performs floating-point division, so `5 / 2` returns `2.5`, which is a float, not an integer. To perform integer division (floor division), the `//` operator should be used, e.g., `5 // 2` returns `2`.",
    "type": "true_false",
    "difficulty": "easy",
    "domain": "python"
  },
  {
    "question": "Explain the concept of database normalization. Discuss the first three normal forms (1NF, 2NF, and 3NF) with examples, and analyze how normalization helps in reducing data redundancy and improving data integrity. Additionally, describe potential drawbacks or trade-offs associated with highly normalized database designs.",
    "answer": "Database normalization is a systematic approach to organizing data in a relational database to minimize redundancy and dependency by dividing large tables into smaller, related tables. The process aims to ensure data consistency and integrity while improving query efficiency. The most commonly used normal forms are the first three: 1NF, 2NF, and 3NF.\n\n1. First Normal Form (1NF): A table is in 1NF if all its attributes contain atomic (indivisible) values, and each record is unique. This means no repeating groups or arrays are allowed. For example, a table storing customer orders should not list multiple products in a single field; instead, each product should be in a separate row.\n\n2. Second Normal Form (2NF): A table is in 2NF if it is in 1NF and all non-key attributes are fully functionally dependent on the entire primary key, not just part of it. This primarily applies to tables with composite primary keys. For example, if a table contains (OrderID, ProductID) as a composite key, attributes like ProductName should depend on ProductID alone, not the whole key. To achieve 2NF, such attributes are moved to separate tables.\n\n3. Third Normal Form (3NF): A table is in 3NF if it is in 2NF and no non-key attribute depends transitively on the primary key. That is, non-key attributes should not depend on other non-key attributes. For example, if a table contains EmployeeID, DepartmentID, and DepartmentName, DepartmentName depends on DepartmentID, not directly on EmployeeID. To reach 3NF, DepartmentName would be moved to a separate Department table.\n\nNormalization reduces data redundancy by ensuring that each piece of information is stored only once. This minimizes anomalies during insertions, updates, and deletions, thus improving data integrity. It also makes maintenance easier and reduces storage requirements.\n\nHowever, highly normalized databases can have drawbacks. They often require more complex joins across multiple tables, which can impact query performance, especially in read-heavy applications. Excessive normalization can also increase the complexity of database design and make it harder for developers unfamiliar with the schema to write efficient queries. In some scenarios, denormalization is intentionally used to optimize performance or simplify reporting, balancing redundancy with speed.\n\nIn summary, normalization up to 3NF is a foundational technique in relational database design that improves data organization and integrity but needs to be balanced against performance considerations depending on the application context.",
    "type": "essay",
    "difficulty": "medium",
    "domain": "databases"
  },
  {
    "question": "Write a React functional component called `ToggleList` that renders a list of items passed as props. Each item should display a button that toggles the visibility of its description. Implement state management to track which item's description is currently visible, ensuring only one description can be visible at a time. Provide the complete component code.",
    "answer": "```jsx\nimport React, { useState } from 'react';\n\nconst ToggleList = ({ items }) => {\n  // State to keep track of the currently visible item index\n  const [visibleIndex, setVisibleIndex] = useState(null);\n\n  // Handler to toggle visibility\n  const toggleDescription = (index) => {\n    if (visibleIndex === index) {\n      setVisibleIndex(null); // Hide if already visible\n    } else {\n      setVisibleIndex(index); // Show the selected item's description\n    }\n  };\n\n  return (\n    <ul>\n      {items.map((item, index) => (\n        <li key={index} style={{ marginBottom: '1em' }}>\n          <div>\n            <strong>{item.title}</strong>{' '}\n            <button onClick={() => toggleDescription(index)}>\n              {visibleIndex === index ? 'Hide' : 'Show'} Description\n            </button>\n          </div>\n          {visibleIndex === index && (\n            <p style={{ marginTop: '0.5em' }}>{item.description}</p>\n          )}\n        </li>\n      ))}\n    </ul>\n  );\n};\n\nexport default ToggleList;\n```\n\n**Explanation:**\n- The component receives an `items` prop, which is expected to be an array of objects with `title` and `description` properties.\n- `visibleIndex` state holds the index of the item whose description is visible. If `null`, no descriptions are shown.\n- The `toggleDescription` function updates `visibleIndex` to either show or hide the description for the clicked item.\n- Only one description is visible at a time, because setting a new index replaces the old one.\n- The component uses conditional rendering to display the description paragraph only if its index matches `visibleIndex`.\n\nThis approach ensures clear UI behavior and efficient state management for toggling descriptions in a list.",
    "type": "coding",
    "difficulty": "medium",
    "domain": "web development"
  },
  {
    "question": "Discuss the principles and challenges of designing fault-tolerant distributed systems. Explain key fault tolerance techniques such as replication, consensus algorithms, and failure detection. Additionally, analyze how these techniques impact system performance, consistency, and availability, referencing the CAP theorem in your explanation.",
    "answer": "Fault-tolerant distributed systems are designed to continue functioning correctly even in the presence of failures, which is critical for ensuring reliability and availability in large-scale, networked applications. Designing such systems involves understanding the types of failures that can occur\u2014such as node crashes, network partitions, and message losses\u2014and implementing mechanisms to detect, tolerate, and recover from these faults.\n\nKey fault tolerance techniques include:\n\n1. **Replication:** Data and services are duplicated across multiple nodes to provide redundancy. Replication can be synchronous or asynchronous. Synchronous replication ensures strong consistency but may increase latency, while asynchronous replication improves performance but risks stale data.\n\n2. **Consensus Algorithms:** Protocols like Paxos, Raft, and Zab enable a distributed system to agree on a single value or state despite failures and asynchrony. Consensus ensures consistency in replicated state machines by coordinating updates atomically.\n\n3. **Failure Detection:** Systems employ heartbeat mechanisms, timeouts, and monitoring to detect node or service failures quickly. Accurate failure detection is challenging due to network delays and partitions, which can cause false positives.\n\nThese techniques impact system properties as explained by the **CAP theorem**, which states that a distributed system can provide at most two of the following three guarantees simultaneously:\n\n- **Consistency (C):** Every read receives the most recent write or an error.\n- **Availability (A):** Every request receives a non-error response, without guarantee that it contains the most recent write.\n- **Partition tolerance (P):** The system continues to operate despite arbitrary message loss or failure of part of the system.\n\nIn practice, network partitions are inevitable, so systems must choose between consistency and availability. For example, a strongly consistent system using consensus may sacrifice availability during partitions, while highly available systems may serve stale data.\n\nMoreover, fault tolerance mechanisms introduce performance overhead. Replication increases storage and network costs, consensus algorithms add latency due to multiple communication rounds, and failure detection must balance sensitivity and false positives.\n\nIn conclusion, designing fault-tolerant distributed systems requires carefully balancing trade-offs between consistency, availability, and partition tolerance, while employing replication, consensus, and failure detection techniques to meet application requirements and operational constraints.",
    "type": "essay",
    "difficulty": "hard",
    "domain": "software engineering"
  },
  {
    "question": "True or False: A linear search algorithm has a time complexity of O(n) in the worst case.",
    "answer": "True. In a linear search, each element in the list is checked sequentially until the target element is found or the list ends. In the worst case, the algorithm must check every element, resulting in a time complexity of O(n), where n is the number of elements in the list.",
    "type": "true_false",
    "difficulty": "easy",
    "domain": "algorithms"
  },
  {
    "question": "True or False: In Python, functions defined inside another function can access and modify variables from the enclosing function's scope directly without using the 'nonlocal' keyword.",
    "answer": "False. In Python, an inner function can access variables from its enclosing function's scope (a closure), but it cannot modify those variables directly unless the 'nonlocal' keyword is used. Without 'nonlocal', assignments to variables inside the inner function will create new local variables, leaving the outer variables unchanged.",
    "type": "true_false",
    "difficulty": "hard",
    "domain": "python"
  },
  {
    "question": "True or False: The Breadth-First Search (BFS) algorithm uses a queue data structure to keep track of the next nodes to visit.",
    "answer": "True. Breadth-First Search (BFS) explores nodes level by level starting from the source node. It uses a queue to store nodes that need to be explored next, ensuring nodes are visited in the order they are discovered.",
    "type": "true_false",
    "difficulty": "easy",
    "domain": "algorithms"
  },
  {
    "question": "Explain the concept of recursion in algorithms. Describe how a recursive function works, including the importance of base cases and recursive cases. Provide a simple example of a recursive algorithm, such as calculating the factorial of a number, and discuss the advantages and potential drawbacks of using recursion.",
    "answer": "Recursion in algorithms refers to the technique where a function calls itself in order to solve a problem by breaking it down into smaller, more manageable subproblems. A recursive function works by defining two key parts: the base case and the recursive case. The base case is the condition under which the recursion stops, preventing infinite calls, while the recursive case is where the function calls itself with a modified argument that moves the problem closer to the base case.\n\nFor example, consider the factorial function, which multiplies a positive integer by all the positive integers less than it. The factorial of n (denoted as n!) can be defined recursively as:\n- Base case: factorial(0) = 1\n- Recursive case: factorial(n) = n * factorial(n - 1) for n > 0\n\nIn code, this can be implemented as:\n\n```python\ndef factorial(n):\n    if n == 0:\n        return 1  # base case\n    else:\n        return n * factorial(n - 1)  # recursive case\n```\n\nAdvantages of recursion include simpler and more elegant code for problems that have a natural recursive structure, such as tree traversals, divide and conquer algorithms, and combinatorial problems. However, recursion can also have drawbacks, such as increased memory usage due to function call stack overhead and the risk of stack overflow if the recursion depth is too large. Additionally, some recursive solutions can be less efficient than their iterative counterparts if not optimized properly, for example, by using memoization or tail recursion.\n\nIn summary, recursion is a powerful concept in algorithms that allows problems to be solved by self-referential function calls, but it must be used thoughtfully with clear base cases to ensure correctness and efficiency.",
    "type": "essay",
    "difficulty": "easy",
    "domain": "algorithms"
  },
  {
    "question": "Critically evaluate the security challenges unique to multi-tenant cloud environments. Discuss how isolation mechanisms such as virtualization and containerization address these challenges. Additionally, analyze the limitations of these mechanisms and propose advanced strategies to enhance data confidentiality and integrity in shared cloud infrastructures.",
    "answer": "Multi-tenant cloud environments, where multiple users or organizations share the same physical infrastructure and resources, present unique security challenges primarily due to resource sharing and potential attack surfaces. The key security concerns include data leakage between tenants, side-channel attacks, unauthorized access, and compliance with data privacy regulations.\n\nIsolation mechanisms like virtualization and containerization are fundamental in mitigating these risks. Virtualization creates isolated virtual machines (VMs) on the same physical hardware, each running its own operating system and applications, thereby providing strong separation at the hardware abstraction level. Containerization, on the other hand, isolates applications within containers that share the host OS kernel but operate in separate user spaces, offering lightweight and efficient isolation.\n\nWhile virtualization offers robust isolation, it incurs performance overhead due to emulating hardware, and vulnerabilities in hypervisors can potentially allow attacks across VMs. Containerization is more efficient but provides weaker isolation since containers share the same kernel; kernel exploits or misconfigurations can lead to container breakout attacks.\n\nTo enhance data confidentiality and integrity beyond these mechanisms, advanced strategies include employing hardware-based security features such as Trusted Execution Environments (TEEs) like Intel SGX, which enable secure enclaves for sensitive computation. Implementing strong encryption for data at rest and in transit, coupled with key management services, ensures that even if isolation is breached, data remains protected. Additionally, continuous monitoring and anomaly detection using AI-driven security analytics can identify and respond to suspicious activities promptly.\n\nAnother approach is the adoption of confidential computing paradigms that protect data in use, not just at rest or in transit, further strengthening tenant isolation. Policy-based access controls and rigorous identity and access management (IAM) also play crucial roles in enforcing least privilege principles.\n\nIn summary, while virtualization and containerization form the backbone of tenant isolation in multi-tenant clouds, their limitations necessitate layered, defense-in-depth strategies combining hardware security, encryption, monitoring, and strict access controls to robustly protect data confidentiality and integrity in shared cloud infrastructures.",
    "type": "essay",
    "difficulty": "hard",
    "domain": "Cloud Computing"
  },
  {
    "question": "True or False: AI systems should always prioritize maximizing accuracy over addressing potential biases to ensure the best overall performance.",
    "answer": "False. While maximizing accuracy is important, prioritizing it without addressing potential biases can lead to unfair or unethical outcomes. AI systems must balance accuracy with fairness, transparency, and inclusivity to avoid perpetuating discrimination and harm. Ignoring bias can undermine trust, legality, and social acceptability of AI applications.",
    "type": "true_false",
    "difficulty": "medium",
    "domain": "AI Ethics"
  },
  {
    "question": "Write a Python function `flatten_dict` that takes a nested dictionary and returns a new dictionary with all nested keys flattened into a single level, joined by dots (`.`). For example, given `{'a': {'b': 1, 'c': 2}, 'd': 3}`, the function should return `{'a.b': 1, 'a.c': 2, 'd': 3}`. Ensure your implementation handles arbitrary depth of nesting.",
    "answer": "Here is a Python implementation of the `flatten_dict` function:\n\n```python\n\ndef flatten_dict(d, parent_key='', sep='.'):\n    items = {}\n    for k, v in d.items():\n        new_key = parent_key + sep + k if parent_key else k\n        if isinstance(v, dict):\n            items.update(flatten_dict(v, new_key, sep=sep))\n        else:\n            items[new_key] = v\n    return items\n\n# Example usage:\nnested_dict = {'a': {'b': 1, 'c': 2}, 'd': 3}\nprint(flatten_dict(nested_dict))\n# Output: {'a.b': 1, 'a.c': 2, 'd': 3}\n```\n\n**Explanation:**\n- The function uses recursion to traverse the dictionary.\n- The `parent_key` accumulates the keys encountered so far, separated by `.`.\n- When a value is a nested dictionary, the function recursively flattens it.\n- When a value is not a dictionary, it assigns the combined key to that value.\n\n**This approach handles dictionaries nested to any depth** and produces a flattened dictionary with dot-separated keys.",
    "type": "coding",
    "difficulty": "medium",
    "domain": "software engineering"
  },
  {
    "question": "Which of the following is a common benefit of using cloud computing services?",
    "answer": "The correct answer is: Scalability. Cloud computing allows businesses to easily scale their resources up or down based on demand without the need for significant upfront hardware investment. This flexibility helps optimize costs and handle varying workloads efficiently.",
    "type": "mcq",
    "difficulty": "easy",
    "domain": "Cloud Computing"
  },
  {
    "question": "Explain the concept of serverless computing in cloud environments. Discuss how serverless architectures differ from traditional cloud-based architectures in terms of resource management, scalability, and cost. Illustrate the benefits and potential drawbacks of adopting serverless computing for application development.",
    "answer": "Serverless computing is a cloud computing execution model where the cloud provider dynamically manages the allocation and provisioning of servers. Unlike traditional cloud-based architectures where developers need to manage infrastructure, serverless abstracts this layer, allowing developers to focus solely on writing code. In serverless architectures, applications are typically broken down into small, stateless functions that execute in response to events, commonly known as Function-as-a-Service (FaaS).\n\nOne of the primary differences between serverless and traditional cloud architectures lies in resource management. In traditional models, resources like virtual machines or containers must be provisioned and maintained, often leading to over-provisioning or under-utilization. Serverless, however, automatically scales resources up or down based on demand, charging only for actual compute time used rather than pre-allocated capacity.\n\nScalability in serverless is inherently built-in; the platform can instantly scale to accommodate any number of concurrent requests without manual intervention. Traditional architectures typically require careful planning and configuration to handle scaling, often involving load balancers and autoscaling groups.\n\nCost-wise, serverless can be more economical for workloads with variable or unpredictable traffic since billing is based on execution time and resource consumption rather than fixed capacity. However, for consistently high workloads, traditional provisioned resources may prove more cost-effective.\n\nBenefits of serverless computing include reduced operational overhead, faster deployment cycles, automatic scaling, and a pay-per-use pricing model. However, potential drawbacks include cold start latency (delays when functions are invoked after inactivity), limited execution time for functions, challenges in debugging and monitoring, vendor lock-in risks, and constraints around long-running or stateful applications.\n\nIn summary, serverless computing offers a compelling alternative to traditional cloud architectures by simplifying resource management and scaling, enabling developers to build and deploy applications more efficiently. Nevertheless, it requires careful consideration of application requirements, particularly regarding performance, state management, and cost patterns.",
    "type": "essay",
    "difficulty": "medium",
    "domain": "Cloud Computing"
  },
  {
    "question": "Implement a custom PyTorch module called `ScaledDotProductAttention` that computes the scaled dot-product attention mechanism used in Transformer models. Your implementation should take three inputs: queries (Q), keys (K), and values (V), each as tensors of shape `(batch_size, seq_len, d_model)`. The module should compute attention scores, apply a softmax to obtain attention weights, and return the weighted sum of the values. Additionally, include an optional boolean argument `mask` to apply a mask that prevents attention to certain positions (e.g., for causal masking in autoregressive models). Write the full PyTorch class with the forward method and demonstrate its usage with random input tensors.",
    "answer": "```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass ScaledDotProductAttention(nn.Module):\n    def __init__(self):\n        super(ScaledDotProductAttention, self).__init__()\n\n    def forward(self, Q, K, V, mask=None):\n        \"\"\"\n        Q, K, V: Tensors of shape (batch_size, seq_len, d_model)\n        mask: Optional tensor broadcastable to (batch_size, seq_len, seq_len), with 0s where positions should be masked\n        \"\"\"\n        d_k = Q.size(-1)\n        # Compute raw attention scores\n        scores = torch.bmm(Q, K.transpose(1, 2)) / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n        \n        if mask is not None:\n            # Mask out positions by setting them to a very negative value\n            scores = scores.masked_fill(mask == 0, float('-inf'))\n\n        # Apply softmax to get attention weights\n        attn_weights = F.softmax(scores, dim=-1)\n\n        # Compute the weighted sum of values\n        output = torch.bmm(attn_weights, V)\n        return output, attn_weights\n\n# Example usage:\nbatch_size = 2\nseq_len = 4\nd_model = 8\n\n# Random tensors simulating queries, keys, and values\nQ = torch.randn(batch_size, seq_len, d_model)\nK = torch.randn(batch_size, seq_len, d_model)\nV = torch.randn(batch_size, seq_len, d_model)\n\n# Create a causal mask to prevent attention to future positions\nmask = torch.tril(torch.ones(seq_len, seq_len)).unsqueeze(0).repeat(batch_size, 1, 1)  # shape (batch_size, seq_len, seq_len)\n\nattention = ScaledDotProductAttention()\noutput, attn_weights = attention(Q, K, V, mask=mask)\n\nprint(\"Output shape:\", output.shape)          # Expected: (batch_size, seq_len, d_model)\nprint(\"Attention weights shape:\", attn_weights.shape)  # Expected: (batch_size, seq_len, seq_len)\n```",
    "type": "coding",
    "difficulty": "hard",
    "domain": "Deep Learning"
  },
  {
    "question": "True or False: In machine learning, increasing the number of features without any feature selection or dimensionality reduction always improves the model's performance.",
    "answer": "False. Increasing the number of features without proper feature selection or dimensionality reduction can lead to overfitting, increased computational cost, and the curse of dimensionality. This often degrades model performance rather than improving it, especially if many features are irrelevant or noisy.",
    "type": "true_false",
    "difficulty": "medium",
    "domain": "machine learning"
  },
  {
    "question": "True or False: A stack data structure follows the First In, First Out (FIFO) principle.",
    "answer": "False. A stack data structure follows the Last In, First Out (LIFO) principle, meaning the most recently added element is the first to be removed.",
    "type": "true_false",
    "difficulty": "easy",
    "domain": "data structures"
  },
  {
    "question": "Discuss the role and importance of convolutional neural networks (CNNs) in computer vision. Explain how CNNs differ from traditional fully connected neural networks in processing visual data. Additionally, describe the key components of a CNN architecture, including convolutional layers, pooling layers, and fully connected layers, and how each contributes to feature extraction and classification tasks.",
    "answer": "Convolutional Neural Networks (CNNs) have revolutionized computer vision by providing powerful models capable of automatically learning hierarchical feature representations from raw image data. Unlike traditional fully connected neural networks, which treat input data as a flat vector and ignore spatial relationships, CNNs preserve the spatial structure of images by using local connections and parameter sharing. This makes CNNs particularly well-suited for image processing tasks.\n\nCNNs differ from fully connected networks primarily in their architecture. Instead of connecting every input neuron to every output neuron, CNNs use convolutional layers where filters (kernels) slide over the input data to detect local patterns such as edges, textures, or more complex features. This local connectivity reduces the number of parameters, improving computational efficiency and reducing overfitting.\n\nKey components of a CNN include:\n\n1. **Convolutional Layers:** These layers apply multiple filters to the input, generating feature maps that highlight the presence of specific patterns. Each filter is trained to recognize a distinct feature, and because the same filter is applied across the entire image, CNNs exploit spatial invariance.\n\n2. **Pooling Layers:** Pooling (such as max pooling or average pooling) reduces the spatial dimensions of feature maps, making the representations more compact and invariant to small translations or distortions in the input. This downsampling helps reduce computational load and controls overfitting.\n\n3. **Fully Connected Layers:** After several convolutional and pooling layers, the network typically includes one or more fully connected layers. These layers integrate the extracted features to perform high-level reasoning, such as classification or regression. By connecting all neurons, they combine the spatially extracted features into final output predictions.\n\nIn summary, CNNs are critical in computer vision because they effectively capture spatial hierarchies in images through convolution and pooling, enabling robust feature extraction and accurate classification. Their specialized architecture addresses the challenges of image data that traditional fully connected networks cannot efficiently handle.",
    "type": "essay",
    "difficulty": "medium",
    "domain": "Computer vision"
  },
  {
    "question": "In a persistent data structure, which of the following statements about partial persistence is TRUE?",
    "answer": "Partial persistence allows access to all previous versions of the data structure for queries, but updates can only be made to the latest version. This means you can read any version but only modify the newest one, enabling efficient version control without duplicating the entire structure. In contrast, full persistence allows both queries and updates on any version, and ephemeral data structures support only the latest version with no access to prior states.",
    "type": "mcq",
    "difficulty": "hard",
    "domain": "data structures"
  },
  {
    "question": "Explain the concept of version control in software engineering. Discuss why version control systems are important in collaborative software development, and describe the basic functionalities they provide. Additionally, highlight the differences between centralized and distributed version control systems.",
    "answer": "Version control is a system that records changes to files or sets of files over time so that specific versions can be recalled later. In software engineering, version control is essential because it allows multiple developers to work on the same codebase simultaneously without overwriting each other's work. It also provides a history of changes, enabling developers to track, review, and revert to previous versions if necessary. Basic functionalities of version control systems include committing changes, branching and merging code, viewing change history, and resolving conflicts. Centralized version control systems (CVCS), such as Subversion (SVN), use a single central server that holds the main repository, and developers check out and commit changes to this server. Distributed version control systems (DVCS), like Git, allow each developer to have a complete copy of the repository, enabling local commits and more flexible workflows. DVCS typically offer better support for offline work and easier branching and merging. Both types have their advantages, but distributed systems have become more popular due to their flexibility and robustness in handling collaboration.",
    "type": "essay",
    "difficulty": "easy",
    "domain": "software engineering"
  },

  {
    "question": "Which of the following SQL isolation levels allows a transaction to read data that has been modified by other uncommitted transactions, potentially leading to dirty reads?",
    "answer": "The SQL isolation level that allows a transaction to read uncommitted changes made by other transactions is called READ UNCOMMITTED. This level does not place any locks to prevent other transactions from reading data that is being modified but not yet committed, which can result in dirty reads. Higher isolation levels like READ COMMITTED, REPEATABLE READ, and SERIALIZABLE provide increasing degrees of protection against such phenomena by restricting visibility of uncommitted changes.",
    "type": "mcq",
    "difficulty": "medium",
    "domain": "databases"
  },
  {
    "question": "Discuss the challenges and methodologies involved in addressing the problem of catastrophic forgetting in continual learning for neural networks. Explain the primary types of approaches used to mitigate forgetting, such as regularization-based, replay-based, and parameter isolation methods. Evaluate the strengths and limitations of these approaches, and propose potential future research directions to improve lifelong learning capabilities in artificial neural networks.",
    "answer": "Catastrophic forgetting refers to the tendency of neural networks to abruptly lose previously acquired knowledge upon learning new tasks sequentially. This phenomenon poses a significant barrier to continual learning, where models are expected to learn from a stream of tasks without forgetting earlier ones. The core challenge arises because standard training updates the model parameters to optimize performance on the current task, often at the expense of overwriting representations useful for prior tasks.\n\nSeveral methodologies have been proposed to mitigate catastrophic forgetting, broadly categorized into three main groups: regularization-based methods, replay-based methods, and parameter isolation methods.\n\n1. Regularization-based Methods:\n   These approaches constrain the update of model parameters to preserve knowledge important for previous tasks. Techniques like Elastic Weight Consolidation (EWC) estimate the importance of each parameter by approximating the Fisher information matrix and penalize changes to crucial weights. Similarly, Synaptic Intelligence (SI) accumulates importance measures during training to regularize parameter updates.\n   - Strengths: They do not require storing data from previous tasks, making them memory efficient and privacy-friendly.\n   - Limitations: Their performance degrades when tasks are highly dissimilar or when the number of tasks is large. They may also struggle with significant distribution shifts.\n\n2. Replay-based Methods:\n   These involve storing a subset of data from previous tasks (experience replay) or generating pseudo-data via generative models (generative replay) to rehearse past knowledge alongside new tasks.\n   - Strengths: They effectively maintain performance across diverse tasks by interleaving old and new data.\n   - Limitations: Storing real data may be infeasible due to memory or privacy constraints, and generative models can be complex and computationally expensive.\n\n3. Parameter Isolation Methods:\n   These allocate distinct subsets of the network\u2019s parameters to different tasks, either by expanding the network dynamically or by masking parameters.\n   - Strengths: They prevent interference by design and often achieve strong task-specific performance.\n   - Limitations: They can lead to unbounded model growth and inefficiency in parameter usage.\n\nFuture research directions include developing hybrid approaches that combine the strengths of these methods, such as memory-efficient replay with adaptive regularization. Another promising direction is meta-learning frameworks that enable models to rapidly adapt to new tasks while retaining previous knowledge. Additionally, exploring biologically inspired mechanisms like synaptic consolidation and neurogenesis may provide insights for more robust lifelong learning. Finally, benchmarking continual learning models on more realistic, complex task sequences remains crucial to advance practical deployment.",
    "type": "essay",
    "difficulty": "hard",
    "domain": "machine learning"
  },
  {
    "question": "Write a Python function `count_vowels(s)` that takes a string `s` as input and returns the number of vowels (`a`, `e`, `i`, `o`, `u`, both uppercase and lowercase) in the string. Demonstrate the function with the input `'Hello, World!'`.",
    "answer": "```python\ndef count_vowels(s):\n    vowels = 'aeiouAEIOU'\n    count = 0\n    for char in s:\n        if char in vowels:\n            count += 1\n    return count\n\n# Example usage:\ninput_str = 'Hello, World!'\nprint(count_vowels(input_str))  # Output: 3\n```",
    "type": "coding",
    "difficulty": "easy",
    "domain": "python"
  },
  {
    "question": "Explain the concept of database normalization. Discuss its main goals and describe the first three normal forms (1NF, 2NF, and 3NF) with examples. Why is normalization important in designing relational databases, and what are some potential drawbacks of over-normalization?",
    "answer": "Database normalization is a systematic process used in designing relational databases to minimize redundancy and dependency by organizing fields and table relations. The main goals of normalization are to eliminate data anomalies (such as insertion, update, and deletion anomalies), reduce data redundancy, and ensure data integrity.\n\nThe first three normal forms are fundamental steps in normalization:\n\n1. First Normal Form (1NF): A table is in 1NF if all its attributes contain only atomic (indivisible) values, and each record is unique. For example, instead of storing multiple phone numbers in one field, each phone number should be stored in a separate row or linked table.\n\n2. Second Normal Form (2NF): A table is in 2NF if it is already in 1NF and all non-key attributes are fully functionally dependent on the entire primary key. This means that if the primary key is composite, no attribute should depend on only part of it. For instance, in a table with a composite key (StudentID, CourseID), fields like StudentName should not depend on CourseID.\n\n3. Third Normal Form (3NF): A table is in 3NF if it is in 2NF and all the attributes are not only dependent on the primary key but also independent of each other. In other words, there should be no transitive dependency. For example, if a table contains StudentID, AdvisorID, and AdvisorName, AdvisorName depends on AdvisorID, not directly on StudentID, so it should be moved to a separate Advisor table.\n\nNormalization is important because it improves database efficiency by preventing data duplication and ensuring consistency. It simplifies maintenance and updates by localizing changes to relevant tables.\n\nHowever, over-normalization can lead to excessive table joins, which might degrade performance during data retrieval. In some cases, denormalization (intentionally introducing redundancy) is used to optimize read-heavy applications. Therefore, database designers must balance normalization with performance needs.",
    "type": "essay",
    "difficulty": "easy",
    "domain": "databases"
  },
  {
    "question": "True or False: The Bellman-Ford algorithm can detect negative weight cycles reachable from the source node but cannot find the shortest paths if any negative weight cycles exist in the graph.",
    "answer": "True. The Bellman-Ford algorithm is designed to compute shortest paths from a single source in graphs that may contain negative weight edges. It can detect the presence of negative weight cycles reachable from the source by performing an additional relaxation step after |V|-1 iterations. If any edge can still be relaxed, it indicates a negative weight cycle. However, if such a cycle exists, shortest paths are undefined (can be infinitely decreased), so the algorithm cannot provide correct shortest path values in this case. Therefore, while Bellman-Ford detects negative cycles, it cannot find shortest paths if these cycles are present.",
    "type": "true_false",
    "difficulty": "hard",
    "domain": "algorithms"
  },
  {
    "question": "Explain the concept of cloud service models: Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS). Compare and contrast these models in terms of their offerings, user responsibilities, and typical use cases.",
    "answer": "Cloud service models define different levels of abstraction and management in cloud computing, offering varying degrees of control and convenience to the user. \n\nInfrastructure as a Service (IaaS) provides virtualized computing resources over the internet. Users get access to fundamental components such as virtual machines, storage, and networks. They are responsible for managing operating systems, applications, and runtime environments, while the cloud provider manages the physical hardware. Typical use cases include hosting websites, data storage, and development/testing environments where users need flexible and scalable infrastructure without investing in physical servers.\n\nPlatform as a Service (PaaS) offers a higher level of abstraction by providing a platform that includes operating systems, development tools, database management, and middleware. Users focus on deploying and managing their applications without worrying about the underlying infrastructure. The provider handles the infrastructure and platform maintenance. PaaS is ideal for developers who want to build applications quickly without managing hardware or software layers, such as web application development and API hosting.\n\nSoftware as a Service (SaaS) delivers fully functional software applications over the internet, accessible via web browsers or thin clients. Users simply consume the software without managing infrastructure, platforms, or application code. The cloud provider handles all aspects including updates, security, and maintenance. Common examples include email services, customer relationship management (CRM) systems, and office productivity tools.\n\nIn summary, IaaS offers maximum control and flexibility with more user responsibility, PaaS balances control and convenience focused on application development, and SaaS provides ready-to-use software with minimal user management. Choosing between these models depends on the specific needs, technical expertise, and desired level of control of the user or organization.",
    "type": "essay",
    "difficulty": "easy",
    "domain": "Cloud Computing"
  },
  {
    "question": "True or False: In computer vision, the Histogram of Oriented Gradients (HOG) descriptor is primarily used to capture color information from images for object detection tasks.",
    "answer": "False. The Histogram of Oriented Gradients (HOG) descriptor is primarily used to capture gradient orientation and edge information in images, which helps in detecting object shapes and structures. It does not capture color information; instead, it focuses on the distribution of intensity gradients or edge directions, which makes it effective for tasks like pedestrian detection where shape and contour are more important than color.",
    "type": "true_false",
    "difficulty": "medium",
    "domain": "Computer vision"
  },
  {
    "question": "True or False: In microservices architecture, implementing synchronous communication between services always improves system resilience and scalability compared to asynchronous communication.",
    "answer": "False. While synchronous communication can simplify request-response interactions, it often introduces tighter coupling between microservices, increasing latency and reducing fault tolerance. Asynchronous communication, on the other hand, decouples services, enabling better scalability and resilience by allowing services to operate independently and handle failures more gracefully. Therefore, synchronous communication does not always improve resilience and scalability; in many cases, asynchronous communication is preferred for these qualities.",
    "type": "true_false",
    "difficulty": "hard",
    "domain": "software engineering"
  },
  {
    "question": "Given a directed acyclic graph (DAG) with weighted edges, which of the following algorithms is the most efficient for finding the shortest path from a single source to all other vertices, and why?",
    "answer": "The most efficient algorithm for finding shortest paths from a single source in a DAG is the 'Topological Sort-based Shortest Path' algorithm. This algorithm works by first performing a topological sort of the vertices, then relaxing the edges in the order of the topological sort. Since the graph is acyclic, each vertex is processed exactly once, and edges are relaxed only once, leading to a time complexity of O(V + E), where V is the number of vertices and E is the number of edges. This is more efficient than Dijkstra's algorithm (O((V + E) log V)) and Bellman-Ford (O(VE)) for DAGs. Therefore, the correctness comes from the acyclic property allowing a linear ordering, and the efficiency arises from processing each edge and vertex only once without the need for priority queues or repeated relaxations.",
    "type": "mcq",
    "difficulty": "hard",
    "domain": "algorithms"
  },
  {
    "question": "True or False: Cloud computing allows users to scale their computing resources up or down quickly based on demand without needing to invest in physical hardware.",
    "answer": "True. One of the key advantages of cloud computing is its elasticity, which enables users to rapidly scale resources such as compute power, storage, and networking up or down according to their current needs. This flexibility eliminates the requirement for upfront investment in physical infrastructure and allows for cost-efficient resource management.",
    "type": "true_false",
    "difficulty": "easy",
    "domain": "Cloud Computing"
  },
  {
    "question": "Write a Python function using OpenCV and NumPy that performs image segmentation based on k-means clustering of pixel colors in the CIELAB color space. The function should take an image and the number of clusters k as inputs and return a segmented image where each pixel is replaced by the mean color of its cluster in RGB. Additionally, explain why the CIELAB color space is preferred over RGB for this task.",
    "answer": "```python\nimport cv2\nimport numpy as np\n\ndef segment_image_kmeans(image, k):\n    # Convert image from BGR to CIELAB color space\n    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n\n    # Reshape the image to a 2D array of pixels and 3 color values\n    pixel_values = lab_image.reshape((-1, 3))\n    pixel_values = np.float32(pixel_values)\n\n    # Define criteria, number of clusters(K) and apply kmeans()\n    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n    _, labels, centers = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n\n    # Convert centers to uint8 (color values)\n    centers = np.uint8(centers)\n\n    # Map each pixel to the centroid color\n    segmented_data = centers[labels.flatten()]\n\n    # Reshape data back to original image dimensions\n    segmented_image_lab = segmented_data.reshape(image.shape)\n\n    # Convert back from LAB to BGR color space\n    segmented_image_bgr = cv2.cvtColor(segmented_image_lab, cv2.COLOR_LAB2BGR)\n\n    return segmented_image_bgr\n\n# Example usage:\n# image = cv2.imread('image.jpg')\n# segmented = segment_image_kmeans(image, 4)\n# cv2.imshow('Segmented Image', segmented)\n# cv2.waitKey(0)\n# cv2.destroyAllWindows()\n```\n\n**Explanation:**\n\nThe CIELAB color space is preferred over RGB for color-based segmentation because it is designed to be perceptually uniform. This means that Euclidean distances in CIELAB space correspond more closely to human color perception differences than in RGB space. Using k-means clustering in CIELAB space leads to clusters that better represent distinct colors as perceived by humans, which improves segmentation quality. In contrast, RGB distances can be misleading due to its non-uniformity, causing clusters to group colors that are perceptually different or separate colors that appear similar to humans.",
    "type": "coding",
    "difficulty": "hard",
    "domain": "Computer vision"
  },
  {
    "question": "True or False: In relational databases, a foreign key constraint enforces referential integrity by ensuring that every value in the foreign key column must match a primary key value in the referenced table or be NULL.",
    "answer": "True. A foreign key constraint in a relational database ensures referential integrity by requiring that each value in the foreign key column corresponds to an existing primary key value in the referenced table or is NULL. This prevents orphan records and maintains consistency between related tables.",
    "type": "true_false",
    "difficulty": "medium",
    "domain": "databases"
  },
  {
    "question": "Which of the following activation functions is most commonly used in deep learning models because it helps mitigate the vanishing gradient problem while being computationally efficient?",
    "answer": "The ReLU (Rectified Linear Unit) activation function is most commonly used in deep learning models because it outputs zero for negative inputs and a linear identity for positive inputs, which helps mitigate the vanishing gradient problem. Additionally, it is computationally efficient to compute compared to sigmoid or tanh functions.",
    "type": "mcq",
    "difficulty": "easy",
    "domain": "Deep Learning"
  },
  {
    "question": "Discuss the concept of dynamic programming and how it differs from divide and conquer algorithms. Illustrate your explanation with an example problem, such as the Fibonacci sequence or the longest common subsequence, detailing how dynamic programming optimizes the solution. What are the key properties a problem must have to be suitable for dynamic programming, and what are some common pitfalls to avoid when designing a dynamic programming solution?",
    "answer": "Dynamic programming (DP) is an algorithmic technique used to solve problems by breaking them down into simpler subproblems and storing the results of these subproblems to avoid redundant computations. Unlike divide and conquer algorithms, which recursively break a problem into independent subproblems and combine their solutions, dynamic programming applies when subproblems overlap, meaning the same subproblems are solved multiple times. DP solves each subproblem once and caches the result, usually in a table, to optimize performance.\n\nFor example, consider the Fibonacci sequence problem where F(n) = F(n-1) + F(n-2) with base cases F(0) = 0 and F(1) = 1. A naive recursive solution recomputes Fibonacci numbers multiple times, leading to exponential time complexity. Using dynamic programming, we store previously computed Fibonacci values in an array or dictionary. This reduces the time complexity to linear O(n), as each Fibonacci number is computed once.\n\nAnother classic example is the longest common subsequence (LCS) problem, where we find the longest subsequence common to two sequences. DP uses a two-dimensional table to store solutions to subproblems defined by prefixes of the two sequences, building the solution bottom-up.\n\nKey properties for a problem to be suitable for dynamic programming include:\n1. Overlapping Subproblems: The problem can be broken down into subproblems that recur multiple times.\n2. Optimal Substructure: The optimal solution to the problem can be constructed from optimal solutions to its subproblems.\n\nCommon pitfalls when designing DP solutions include:\n- Incorrectly identifying subproblems or dependencies, leading to wrong or inefficient solutions.\n- Forgetting to store computed results, thereby losing the benefit of DP.\n- Using excessive memory by storing unnecessary states.\n- Not carefully defining the order of computation in bottom-up approaches, which may cause referencing uncomputed states.\n\nIn summary, dynamic programming is a powerful method for optimizing problems with overlapping subproblems and optimal substructure, by caching intermediate results to avoid redundant work. Proper problem identification and careful implementation are key to effective DP solutions.",
    "type": "essay",
    "difficulty": "medium",
    "domain": "algorithms"
  },
  {
    "question": "Implement a Python class for a MinStack, a stack data structure that supports push, pop, top operations, and retrieving the minimum element in constant time. Include the methods push(val), pop(), top(), and get_min(). Explain how your implementation achieves O(1) time complexity for all operations.",
    "answer": "Here's a Python implementation of a MinStack:\n\n```python\nclass MinStack:\n    def __init__(self):\n        self.stack = []\n        self.min_stack = []  # Stack to keep track of minimums\n\n    def push(self, val: int) -> None:\n        self.stack.append(val)\n        # Push the new minimum onto min_stack\n        if not self.min_stack or val <= self.min_stack[-1]:\n            self.min_stack.append(val)\n\n    def pop(self) -> None:\n        if self.stack:\n            val = self.stack.pop()\n            # If popped value is the current minimum, pop it from min_stack too\n            if val == self.min_stack[-1]:\n                self.min_stack.pop()\n\n    def top(self) -> int:\n        if self.stack:\n            return self.stack[-1]\n        raise IndexError(\"top from empty stack\")\n\n    def get_min(self) -> int:\n        if self.min_stack:\n            return self.min_stack[-1]\n        raise IndexError(\"get_min from empty stack\")\n```\n\n**Explanation:**\n\n- `self.stack` stores all pushed values.\n- `self.min_stack` keeps track of the minimum values at each state of the main stack.\n- When pushing, if the new value is less than or equal to the current minimum (or if min_stack is empty), it is also pushed onto `min_stack`.\n- When popping, if the popped value equals the current minimum, it is also popped from `min_stack`.\n\nThis ensures that the top of `min_stack` always holds the minimum element of the current stack.\n\nAll operations (`push`, `pop`, `top`, and `get_min`) run in O(1) time because they involve only constant-time stack operations (append/pop on lists) without any iteration or searching.",
    "type": "coding",
    "difficulty": "medium",
    "domain": "data structures"
  },
  {
    "question": "Write a simple PyTorch code snippet to create a single-layer neural network (a linear layer) that takes an input of size 10 and outputs a size of 1. Initialize the network, create a random input tensor, and perform a forward pass to get the output. Explain what the output represents in this context.",
    "answer": "```python\nimport torch\nimport torch.nn as nn\n\n# Define a single-layer neural network\nclass SingleLayerNN(nn.Module):\n    def __init__(self):\n        super(SingleLayerNN, self).__init__()\n        self.linear = nn.Linear(10, 1)  # input size 10, output size 1\n\n    def forward(self, x):\n        return self.linear(x)\n\n# Initialize the network\nmodel = SingleLayerNN()\n\n# Create a random input tensor of size (batch_size=1, input_features=10)\ninput_tensor = torch.randn(1, 10)\n\n# Perform a forward pass\noutput = model(input_tensor)\n\nprint(\"Input:\\n\", input_tensor)\nprint(\"Output:\\n\", output)\n```\n\n**Explanation:**\n- The network consists of a single linear layer that applies a linear transformation to the input: \\( y = Wx + b \\), where \\( W \\) is a weight matrix and \\( b \\) is a bias vector.\n- The input tensor is a randomly generated vector with 10 features.\n- The output is a tensor with size 1, representing the transformed input after the linear layer.\n- In this context, the output can be interpreted as a raw prediction or score before any activation function is applied, useful for regression tasks or as input to further layers in a larger network.",
    "type": "coding",
    "difficulty": "easy",
    "domain": "Deep Learning"
  },
  {
    "question": "True or False: In the QuickSort algorithm, choosing the pivot as the median of the first, middle, and last elements of the array always guarantees the best-case time complexity of O(n log n).",
    "answer": "False. While choosing the pivot as the median of the first, middle, and last elements (median-of-three) is a common heuristic to improve QuickSort's performance and reduce the likelihood of worst-case behavior, it does not guarantee the best-case time complexity of O(n log n) in every case. The pivot selection strategy helps avoid poor partitions but does not ensure perfectly balanced splits every time, so the actual runtime can still degrade depending on the input distribution.",
    "type": "true_false",
    "difficulty": "medium",
    "domain": "algorithms"
  },
  {
    "question": "Which of the following SQL statements is used to remove all rows from a table but keeps the table structure intact for future use?",
    "answer": "The correct answer is TRUNCATE. The TRUNCATE statement removes all rows from a table quickly and efficiently while preserving the table structure and its constraints. Unlike DELETE, which removes rows one at a time and can be slower, TRUNCATE resets any auto-increment counters and cannot be rolled back in some database systems.",
    "type": "mcq",
    "difficulty": "easy",
    "domain": "databases"
  },
  {
    "question": "True or False: Edge detection in computer vision is primarily used to identify significant changes in pixel intensity, which often correspond to object boundaries within an image.",
    "answer": "True. Edge detection algorithms analyze changes in pixel intensity to locate boundaries between objects or regions within an image. These changes often indicate edges where the image brightness shifts sharply, helping to segment and understand the structure of objects in computer vision tasks.",
    "type": "true_false",
    "difficulty": "easy",
    "domain": "Computer vision"
  },
  {
    "question": "Which data structure uses the FIFO (First In, First Out) principle for managing its elements?",
    "answer": "The Queue data structure operates on the FIFO principle, where the first element added is the first one to be removed. This contrasts with a stack, which follows LIFO (Last In, First Out). Queues are commonly used in scenarios such as scheduling and buffering.",
    "type": "mcq",
    "difficulty": "easy",
    "domain": "data structures"
  },
  {
    "question": "Explain the concept of Python's asynchronous programming using the asyncio library. Discuss how the event loop, coroutines, tasks, and futures interact within this model. Provide a detailed example illustrating how to write an asynchronous function that fetches data concurrently from multiple URLs using the aiohttp library. Additionally, analyze the benefits and potential pitfalls of using asyncio compared to traditional multithreading or multiprocessing approaches in Python.",
    "answer": "Python's asynchronous programming model, primarily facilitated by the asyncio library, allows programs to handle IO-bound and high-level structured network code concurrently without the complexity of threading or multiprocessing. At its core, asyncio is built around the concept of an event loop, which is a programming construct that waits for and dispatches events or messages in a program. The event loop runs asynchronous tasks and callbacks, performs network IO operations, and manages subprocesses.\n\nCoroutines are special functions defined with `async def` that can pause their execution at `await` points, allowing the event loop to switch context to other coroutines. This cooperative multitasking enables efficient concurrency without the overhead of multiple threads. Tasks are wrappers around coroutines scheduled to run on the event loop; they track the execution state of coroutines. Futures represent a placeholder for a result that is initially unknown but will be available at some point, often used internally in asyncio to signal completion.\n\nA practical example involves fetching data concurrently from multiple URLs. Using the `aiohttp` library, which supports asynchronous HTTP requests, we can define an async function `fetch` that awaits an HTTP GET request and returns the response text. By creating multiple tasks, each fetching a different URL, and running them concurrently with `asyncio.gather`, we achieve efficient IO-bound concurrency.\n\nExample:\n```python\nimport asyncio\nimport aiohttp\n\nasync def fetch(session, url):\n    async with session.get(url) as response:\n        return await response.text()\n\nasync def main(urls):\n    async with aiohttp.ClientSession() as session:\n        tasks = [asyncio.create_task(fetch(session, url)) for url in urls]\n        results = await asyncio.gather(*tasks)\n        return results\n\nurls = [\n    'https://example.com',\n    'https://python.org',\n    'https://asyncio.org'\n]\n\nif __name__ == '__main__':\n    data = asyncio.run(main(urls))\n    for content in data:\n        print(len(content))\n```\n\nBenefits of asyncio over traditional multithreading/multiprocessing include lower overhead (no need to spawn multiple threads or processes), avoidance of issues like race conditions and deadlocks inherent in threading, and better scalability for IO-bound tasks. However, asyncio has pitfalls: it is single-threaded, so CPU-bound tasks block the event loop and degrade performance; it requires libraries to support async-await natively; and developers must carefully design coroutine interactions to avoid subtle bugs.\n\nIn summary, asyncio provides a powerful paradigm for writing concurrent Python programs optimized for IO-bound operations, leveraging coroutines and event loops for efficient task management while avoiding many complexities of thread-based concurrency.",
    "type": "essay",
    "difficulty": "hard",
    "domain": "python"
  },
  {
    "question": "Which of the following sorting algorithms is known for having the best average-case time complexity of O(n log n)?",
    "answer": "Merge Sort is a divide and conquer sorting algorithm that consistently achieves an average-case time complexity of O(n log n). Unlike algorithms such as Bubble Sort or Insertion Sort, which have average complexities of O(n\u00b2), Merge Sort divides the input array into halves, sorts each half recursively, and then merges the sorted halves efficiently, maintaining the O(n log n) complexity.",
    "type": "mcq",
    "difficulty": "easy",
    "domain": "algorithms"
  },
  {
    "question": "Implement a custom PyTorch autograd Function named `SparseMax` that computes the SparseMax activation function, an alternative to Softmax which produces sparse probability distributions. Your implementation should include both the forward and backward passes. Then, write a short example showing how to use this custom activation in a simple neural network layer. Explain how the backward pass computes the gradient and why this is important for training deep models.",
    "answer": "Below is an implementation of the SparseMax activation as a custom PyTorch autograd Function, including the forward and backward methods. SparseMax maps inputs to sparse probability distributions by projecting onto the simplex and is useful in attention mechanisms where sparsity is desired.\n\n```python\nimport torch\nfrom torch.autograd import Function\n\nclass SparseMax(Function):\n    @staticmethod\n    def forward(ctx, input):\n        # input shape: (batch_size, num_features)\n        input_sorted, _ = torch.sort(input, descending=True, dim=1)\n        input_cumsum = torch.cumsum(input_sorted, dim=1)\n        k = torch.arange(1, input.shape[1] + 1, device=input.device).view(1, -1)\n\n        # Calculate threshold function\n        support = 1 + k * input_sorted > input_cumsum\n        k_z = support.sum(dim=1, keepdim=True)  # number of active elements\n\n        # Compute threshold tau\n        tau_sum = input_cumsum.gather(1, k_z - 1)\n        tau = (tau_sum - 1) / k_z.type(input.dtype)\n\n        output = torch.clamp(input - tau, min=0)\n\n        # Save for backward\n        ctx.save_for_backward(output)\n        return output\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        output, = ctx.saved_tensors\n        nonzeros = output > 0\n        sum_grad = (grad_output * nonzeros).sum(dim=1, keepdim=True)\n        grad_input = nonzeros * (grad_output - sum_grad / nonzeros.sum(dim=1, keepdim=True))\n        return grad_input\n\n# Alias for convenience\nsparsemax = SparseMax.apply\n\n# Example usage in a simple network\nimport torch.nn as nn\n\nclass SimpleNet(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(SimpleNet, self).__init__()\n        self.fc = nn.Linear(input_dim, output_dim)\n\n    def forward(self, x):\n        logits = self.fc(x)\n        return sparsemax(logits)\n\n# Instantiate model and run forward\nmodel = SimpleNet(5, 3)\ninput_tensor = torch.randn(2, 5)\noutput = model(input_tensor)\nprint(\"SparseMax output:\", output)\n\n```\n\n### Explanation of the backward pass:\n\nThe backward pass computes gradients of the loss with respect to the input of the SparseMax function. Since SparseMax projects logits onto a simplex, the gradient is zero for entries where the output is zero (due to clamping), which creates sparsity. For non-zero outputs, the gradient is adjusted by subtracting the average gradient over the active set to ensure the sum of gradients is zero (because outputs live on a simplex and must sum to one). This adjustment is crucial for proper gradient flow and convergence during training.\n\nThis custom autograd function allows SparseMax to be seamlessly integrated into neural networks and trained using standard backpropagation, enabling models to learn sparse probability distributions which can improve interpretability and efficiency in certain deep learning tasks.",
    "type": "coding",
    "difficulty": "hard",
    "domain": "Deep Learning"
  },
  {
    "question": "In the context of ensemble learning, which of the following statements best describes the main difference between Bagging and Boosting methods?",
    "answer": "Bagging (Bootstrap Aggregating) builds multiple independent base learners in parallel on different random subsets of the training data (with replacement) and combines their predictions typically by voting or averaging to reduce variance. Boosting, on the other hand, builds base learners sequentially where each learner attempts to correct the errors of the previous ones by focusing more on misclassified examples, thus reducing bias. Therefore, Bagging primarily reduces variance while Boosting primarily reduces bias.",
    "type": "mcq",
    "difficulty": "medium",
    "domain": "machine learning"
  },
  {
    "question": "Explain the difference between an array and a linked list as data structures. Discuss their respective advantages and disadvantages, including how they manage memory and the implications for common operations such as insertion, deletion, and access.",
    "answer": "Arrays and linked lists are fundamental data structures used to store collections of elements, but they differ significantly in their structure and operation. An array is a contiguous block of memory where elements are stored sequentially. This allows for fast access to any element via its index, with a time complexity of O(1) for access operations. However, arrays have a fixed size (in many languages) and resizing them can be costly because it requires allocating a new block of memory and copying all elements. Inserting or deleting elements, especially in the middle, can also be inefficient since it may require shifting elements, leading to O(n) time complexity.\n\nIn contrast, a linked list consists of nodes where each node contains data and a reference (or pointer) to the next node. The nodes can be scattered anywhere in memory, with their order maintained through these pointers. This structure allows for dynamic memory allocation, so linked lists can easily grow or shrink without the need for resizing. Insertion and deletion operations, particularly at the beginning or middle of the list, are efficient and can be done in O(1) time if the node reference is known, as it only involves changing pointers. However, linked lists have slower access times\u2014O(n) for accessing an element at a specific position\u2014because traversal from the head node is required. Additionally, linked lists use extra memory for storing pointers, which is a disadvantage compared to arrays.\n\nIn summary, arrays are preferable when fast random access and memory efficiency are priorities, while linked lists are better suited for applications requiring frequent insertions and deletions without the overhead of resizing. Understanding these trade-offs helps in selecting the appropriate data structure based on the specific requirements of the problem at hand.",
    "type": "essay",
    "difficulty": "easy",
    "domain": "data structures"
  },
  {
    "question": "Write a Python function called `is_palindrome` that takes a string as input and returns `True` if the string is a palindrome (reads the same forwards and backwards) and `False` otherwise. Ignore case and spaces in the string. Provide a code example demonstrating the function with input \"A man a plan a canal Panama\".",
    "answer": "Here's a Python function that checks if a given string is a palindrome by ignoring case and spaces:\n\n```python\ndef is_palindrome(s: str) -> bool:\n    # Remove spaces and convert to lowercase\n    cleaned = ''.join(c.lower() for c in s if c.isalnum())\n    # Check if cleaned string reads the same forwards and backwards\n    return cleaned == cleaned[::-1]\n\n# Example usage:\ninput_str = \"A man a plan a canal Panama\"\nprint(is_palindrome(input_str))  # Output: True\n```\n\nExplanation:\n- The function first normalizes the input string by removing all non-alphanumeric characters and converting everything to lowercase.\n- It then compares the cleaned string to its reverse.\n- If both are equal, the string is a palindrome.\n\nIn the example, \"A man a plan a canal Panama\" is a well-known palindrome phrase, so the function returns `True`.",
    "type": "coding",
    "difficulty": "easy",
    "domain": "algorithms"
  },
  {
    "question": "Implement a thread-safe LRU (Least Recently Used) cache in Python using only built-in libraries. The cache should support concurrent access from multiple threads without data corruption. Include methods for getting and setting cache entries, and ensure that the cache evicts the least recently used item when capacity is exceeded. Provide a sample usage demonstrating thread-safe behavior with multiple threads accessing and modifying the cache concurrently.",
    "answer": "Here's an implementation of a thread-safe LRU cache in Python using built-in libraries:\n\n```python\nimport threading\nfrom collections import OrderedDict\n\nclass ThreadSafeLRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = OrderedDict()\n        self.lock = threading.Lock()\n\n    def get(self, key):\n        with self.lock:\n            if key not in self.cache:\n                return -1\n            # Move the accessed key to the end to show it was recently used\n            self.cache.move_to_end(key)\n            return self.cache[key]\n\n    def set(self, key, value):\n        with self.lock:\n            if key in self.cache:\n                # Update value and move to end\n                self.cache.move_to_end(key)\n            self.cache[key] = value\n            if len(self.cache) > self.capacity:\n                # Pop the first item (least recently used)\n                self.cache.popitem(last=False)\n\n# Example usage with threads\nimport threading\nimport time\n\ncache = ThreadSafeLRUCache(3)\n\ndef cache_worker(id, operations):\n    for op, key, val in operations:\n        if op == 'get':\n            result = cache.get(key)\n            print(f\"Thread {id}: get({key}) -> {result}\")\n        elif op == 'set':\n            cache.set(key, val)\n            print(f\"Thread {id}: set({key}, {val})\")\n        time.sleep(0.01)  # simulate some delay\n\n# Define operations for each thread\nops1 = [('set', 'a', 1), ('set', 'b', 2), ('get', 'a', None), ('set', 'c', 3)]\nops2 = [('get', 'b', None), ('set', 'd', 4), ('get', 'c', None), ('set', 'e', 5)]\n\nthread1 = threading.Thread(target=cache_worker, args=(1, ops1))\nthread2 = threading.Thread(target=cache_worker, args=(2, ops2))\n\nthread1.start()\nthread2.start()\n\nthread1.join()\nthread2.join()\n\n# Final cache state\nprint(\"Final cache contents:\", list(cache.cache.items()))\n```\n\n### Explanation:\n- The `ThreadSafeLRUCache` class uses an `OrderedDict` to maintain the order of keys by usage. The most recently used key is moved to the end.\n- A `threading.Lock` is used to synchronize access to the cache, preventing race conditions during get/set operations.\n- The `get` method returns the cached value if present, moving the key to mark it as recently used.\n- The `set` method inserts or updates a key-value pair, moves it to the end, and evicts the least recently used item if capacity is exceeded.\n- The example demonstrates concurrent `get` and `set` calls from two threads, ensuring no data corruption.\n\n### Importance:\nThread-safe caches are critical in multi-threaded applications to avoid inconsistent states, data races, or crashes. Using locks ensures atomicity of cache operations while retaining the LRU eviction policy efficiently via `OrderedDict`.",
    "type": "coding",
    "difficulty": "hard",
    "domain": "software engineering"
  },
  {
    "question": "Discuss the design and implementation challenges of persistent (immutable) data structures in functional programming languages. Explain how persistent data structures differ from ephemeral data structures in terms of memory usage, performance trade-offs, and concurrency. Illustrate your answer by describing the internal structure and operational complexity of a persistent balanced binary search tree, such as a persistent red-black tree or AVL tree. Additionally, analyze the advantages of persistent data structures in concurrent and parallel programming environments.",
    "answer": "Persistent data structures are immutable data structures that preserve previous versions of themselves when modified, enabling access to any past version at any time. This contrasts with ephemeral data structures, which overwrite their contents on updates and do not retain historical versions.\n\n**Design and Implementation Challenges:**\n1. **Structural Sharing:** To avoid copying the entire data structure on every update (which would be inefficient), persistent data structures rely heavily on structural sharing. This means that unchanged parts of the data structure are shared between versions, minimizing memory usage.\n2. **Balancing Performance and Memory:** Maintaining balance (e.g., red-black properties) in persistent balanced trees requires carefully implemented algorithms that produce new versions with minimal copying, often by creating new nodes only along the path from the root to the modified node.\n3. **Garbage Collection and Memory Management:** Since multiple versions coexist, efficient garbage collection or reference counting mechanisms are necessary to reclaim memory from versions no longer in use.\n4. **Complexity of Implementation:** Implementing persistent balanced trees is more complex than their ephemeral counterparts due to the need to maintain invariants while generating new versions efficiently.\n\n**Differences Between Persistent and Ephemeral Data Structures:**\n- **Memory Usage:** Persistent structures use more memory due to multiple versions existing simultaneously and the overhead of structural sharing metadata.\n- **Performance Trade-offs:** Updates in persistent structures are typically more expensive than in ephemeral ones because they must create new nodes along the update path, but reads can often be as efficient.\n- **Concurrency:** Persistent data structures are inherently thread-safe because they do not mutate existing versions, making them suitable for concurrent and parallel environments without locks.\n\n**Example: Persistent Balanced Binary Search Tree (e.g., Persistent Red-Black Tree):**\n- Internally, it stores nodes with left and right child pointers, color bits (for red-black properties), and values.\n- On insertion or deletion, instead of modifying nodes in place, new nodes are created along the path from the root to the affected leaf.\n- The rest of the tree is shared with the previous version.\n- The update operations maintain balancing properties by performing rotations and recoloring on the newly created nodes.\n- Operational complexity remains O(log n) for search, insertion, and deletion, similar to ephemeral balanced trees.\n\n**Advantages in Concurrent and Parallel Programming:**\n- Since no version is mutated, multiple threads can safely access and operate on different versions without synchronization overhead.\n- This immutability eliminates race conditions related to shared mutable state.\n- Facilitates easier reasoning about program state and debugging.\n\nIn summary, persistent data structures trade off some update performance and memory overhead to gain immutability and thread-safety. Their design requires careful use of structural sharing and efficient update algorithms, especially in balanced trees, but they offer significant advantages in multi-threaded and functional programming contexts.",
    "type": "essay",
    "difficulty": "hard",
    "domain": "data structures"
  },
  {
    "question": "Discuss the role of design patterns in software engineering. Choose three common design patterns\u2014such as Singleton, Observer, and Factory Method\u2014and explain their purposes, typical use cases, and potential drawbacks. How do design patterns contribute to software maintainability and scalability? Illustrate your explanation with examples.",
    "answer": "Design patterns are reusable solutions to common problems encountered during software development. They provide a standardized approach to solving design issues, promoting code readability, maintainability, and scalability by capturing best practices in a structured format. \n\n1. Singleton Pattern: This pattern ensures that a class has only one instance and provides a global point of access to it. It is typically used for managing shared resources such as configuration settings or logging mechanisms. \n   - Use case: A configuration manager where multiple components need consistent configuration data.\n   - Drawbacks: It can introduce global state, making testing harder and potentially leading to hidden dependencies.\n\n2. Observer Pattern: This pattern defines a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically. \n   - Use case: Implementing event handling systems, such as UI components reacting to user input or data changes.\n   - Drawbacks: Can lead to memory leaks if observers are not properly deregistered and can cause unforeseen side effects due to cascading updates.\n\n3. Factory Method Pattern: This pattern defines an interface for creating an object but lets subclasses decide which class to instantiate. It helps encapsulate object creation, promoting loose coupling. \n   - Use case: A GUI framework that supports multiple platforms, where the factory creates platform-specific UI components.\n   - Drawbacks: Can increase complexity with many subclasses and may introduce unnecessary abstraction if used improperly.\n\nDesign patterns contribute to maintainability by encouraging developers to use proven, well-understood solutions, reducing ad hoc coding and simplifying future changes. They enhance scalability by enabling modular design, which supports extension without modifying existing code (Open/Closed Principle). For example, using Observer allows new observers to be added without altering the subject, while Factory Method supports adding new product types without changing client code.\n\nIn summary, design patterns are essential tools in software engineering that help manage complexity and foster clear communication among developers. However, they should be applied judiciously to avoid over-engineering and unnecessary abstraction.",
    "type": "essay",
    "difficulty": "medium",
    "domain": "software engineering"
  },
  {
    "question": "True or False: In microservices architecture, using synchronous communication between services is generally preferred over asynchronous communication because it simplifies error handling and improves system scalability.",
    "answer": "False. In microservices architecture, asynchronous communication is generally preferred over synchronous communication for improving system scalability and resilience. Asynchronous messaging decouples services, allowing them to operate independently and handle failures more gracefully. While synchronous communication can simplify error handling due to its request-response nature, it often leads to tighter coupling, increased latency, and reduced fault tolerance, which can negatively impact scalability and system robustness.",
    "type": "true_false",
    "difficulty": "hard",
    "domain": "software engineering"
  },
  {
    "question": "In machine learning, which of the following statements best describes the primary purpose of the dropout technique during training of deep neural networks?",
    "answer": "Dropout is a regularization technique designed to prevent overfitting by randomly 'dropping out' (setting to zero) a subset of neurons during each training iteration. This forces the network to not rely too heavily on any particular neurons, promoting redundancy and robustness in learned representations. During inference, all neurons are used but their outputs are typically scaled to account for the dropout during training. This technique helps improve generalization performance on unseen data.",
    "type": "mcq",
    "difficulty": "medium",
    "domain": "machine learning"
  },
  {
    "question": "Write a Python function called `count_vowels` that takes a string as input and returns the number of vowels (a, e, i, o, u) in the string, ignoring case. Demonstrate the function with the input \"Hello World!\".",
    "answer": "Here's a simple implementation of the `count_vowels` function:\n\n```python\ndef count_vowels(s):\n    vowels = 'aeiou'\n    count = 0\n    for char in s.lower():\n        if char in vowels:\n            count += 1\n    return count\n\n# Example usage\ninput_string = \"Hello World!\"\nprint(count_vowels(input_string))  # Output: 3\n```\n\nExplanation:\n- The function converts the input string to lowercase to handle case insensitivity.\n- It iterates over each character and checks if it is in the string of vowels.\n- If yes, it increments the count.\n- Finally, it returns the total count.\n\nFor the input \"Hello World!\", the vowels are 'e', 'o', and 'o', so the function returns 3.",
    "type": "coding",
    "difficulty": "easy",
    "domain": "python"
  },
  {
    "question": "Write a Python function `serialize_tree` that serializes a binary tree into a string using preorder traversal, where null nodes are represented by the character '#'. Then, implement a `deserialize_tree` function that takes such a string and reconstructs the original binary tree. Provide a usage example demonstrating serialization and deserialization, and explain why this approach is effective for tree persistence or transmission.",
    "answer": "```python\nclass TreeNode:\n    def __init__(self, val=0, left=None, right=None):\n        self.val = val\n        self.left = left\n        self.right = right\n\ndef serialize_tree(root):\n    def preorder(node):\n        if not node:\n            return ['#']\n        return [str(node.val)] + preorder(node.left) + preorder(node.right)\n    return ','.join(preorder(root))\n\ndef deserialize_tree(data):\n    def build(nodes):\n        val = next(nodes)\n        if val == '#':\n            return None\n        node = TreeNode(int(val))\n        node.left = build(nodes)\n        node.right = build(nodes)\n        return node\n    nodes = iter(data.split(','))\n    return build(nodes)\n\n# Example Usage:\n# Construct a binary tree:\n#     1\n#    / \\\n#   2   3\n#      / \\\n#     4   5\n\nroot = TreeNode(1, TreeNode(2), TreeNode(3, TreeNode(4), TreeNode(5)))\nserialized = serialize_tree(root)\nprint('Serialized:', serialized)  # Output: Serialized: 1,2,#,#,3,4,#,#,5,#,#\n\ndeserialized_root = deserialize_tree(serialized)\nprint('Deserialized root value:', deserialized_root.val)  # Output: 1\n\n# Explanation:\n# This serialization uses preorder traversal and includes placeholders '#' for null children.\n# This ensures that the tree structure is fully captured, allowing exact reconstruction.\n# The approach is effective for persistence or transmission because it is a compact, linear\n# representation that can be stored in a file or sent over a network and later deserialized\n# back to the original tree structure without ambiguity.",
    "type": "coding",
    "difficulty": "medium",
    "domain": "software engineering"
  },
  {
    "question": "Implement a Python function that performs image stitching to create a panorama from two overlapping images. Your function should detect feature points using SIFT, match features, compute a homography matrix using RANSAC to handle outliers, and finally warp and blend the images to produce a seamless panorama. Demonstrate your function on two sample images and explain each step in your implementation.",
    "answer": "Below is a detailed implementation of image stitching using OpenCV and numpy:\n\n```python\nimport cv2\nimport numpy as np\n\ndef stitch_images(img1, img2):\n    # Step 1: Detect SIFT features and compute descriptors\n    sift = cv2.SIFT_create()\n    keypoints1, descriptors1 = sift.detectAndCompute(img1, None)\n    keypoints2, descriptors2 = sift.detectAndCompute(img2, None)\n\n    # Step 2: Match descriptors using FLANN matcher\n    FLANN_INDEX_KDTREE = 1\n    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n    search_params = dict(checks=50)\n    flann = cv2.FlannBasedMatcher(index_params, search_params)\n    matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n\n    # Step 3: Apply Lowe's ratio test to filter good matches\n    good_matches = []\n    for m, n in matches:\n        if m.distance < 0.7 * n.distance:\n            good_matches.append(m)\n\n    if len(good_matches) < 4:\n        raise ValueError(\"Not enough good matches to compute homography.\")\n\n    # Step 4: Extract location of good matches\n    src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n    dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n\n    # Step 5: Compute homography using RANSAC to handle outliers\n    H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n\n    # Step 6: Warp img1 to img2's plane\n    height_img2, width_img2 = img2.shape[:2]\n    height_img1, width_img1 = img1.shape[:2]\n\n    # Compute size of panorama canvas\n    corners_img1 = np.float32([[0,0], [0,height_img1], [width_img1, height_img1], [width_img1, 0]]).reshape(-1,1,2)\n    warped_corners_img1 = cv2.perspectiveTransform(corners_img1, H)\n    corners_img2 = np.float32([[0,0], [0,height_img2], [width_img2, height_img2], [width_img2, 0]]).reshape(-1,1,2)\n\n    all_corners = np.concatenate((warped_corners_img1, corners_img2), axis=0)\n\n    [x_min, y_min] = np.int32(all_corners.min(axis=0).ravel() - 0.5)\n    [x_max, y_max] = np.int32(all_corners.max(axis=0).ravel() + 0.5)\n\n    translation_dist = [-x_min, -y_min]\n\n    # Step 7: Warp img1 with translation\n    H_translation = np.array([[1, 0, translation_dist[0]],\n                              [0, 1, translation_dist[1]],\n                              [0, 0, 1]])\n\n    panorama = cv2.warpPerspective(img1, H_translation.dot(H), (x_max - x_min, y_max - y_min))\n\n    # Step 8: Paste img2 into panorama\n    panorama[translation_dist[1]:height_img2 + translation_dist[1], \n             translation_dist[0]:width_img2 + translation_dist[0]] = img2\n\n    # Step 9: Optional - blending to reduce seam visibility (simple averaging in overlap)\n    # This implementation uses simple overlay; advanced blending like multi-band blending can be added\n\n    return panorama\n\n\n# Example usage:\nif __name__ == '__main__':\n    img1 = cv2.imread('left.jpg')  # Image on the left\n    img2 = cv2.imread('right.jpg')  # Image on the right\n\n    if img1 is None or img2 is None:\n        raise FileNotFoundError('Input images not found.')\n\n    panorama = stitch_images(img1, img2)\n\n    cv2.imwrite('panorama.jpg', panorama)\n    cv2.imshow('Panorama', panorama)\n    cv2.waitKey(0)\n    cv2.destroyAllWindows()\n```\n\n### Explanation:\n1. **Feature Detection (SIFT):** Detects distinctive keypoints and descriptors in both images.\n2. **Feature Matching:** Uses FLANN-based matcher to find nearest neighbors for descriptors and applies Lowe's ratio test to keep only good matches.\n3. **Homography Estimation:** Computes the perspective transformation matrix (homography) from matched points using RANSAC to reject outliers.\n4. **Warping:** Applies the homography to warp the first image onto the coordinate space of the second image.\n5. **Canvas Size Calculation:** Determines the size of the output panorama to accommodate both images.\n6. **Image Blending:** Overlays the second image onto the warped first image. More sophisticated blending methods can be used to improve seam quality.\n\nThis method is fundamental in computer vision for panorama creation and demonstrates key concepts including feature detection, robust model estimation, and image warping.",
    "type": "coding",
    "difficulty": "hard",
    "domain": "Computer vision"
  }
]